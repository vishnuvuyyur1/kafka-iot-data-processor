# kafka-iot-data-processor
Kafka project <br>
![arc](https://user-images.githubusercontent.com/22782834/88284944-93ab9600-ccee-11ea-9790-5357636d209f.png)
- A pipeline architecture that consists of well-known open source tools to specifically integrate internet of things (IoT) data streams.
- The code demonstrate how to deal with IoT stream data that is generated by device equipped with sensing components(IOT devices) 
   by utilizing open source tools and frameworks to tackle data integration as well as scalable stream processing.  
- The architecture consists of several tools that are chained to build a pipeline. Apache Kafka a
  suitable intermediate tool for the data integration kicks in by triggering a schedule task which send out a value every second mimicing an IOT device as the entry point of published messages, 
- These messages are then forwarded to a Kafka broker running locally in order to fault-tolerant stream processing and parallel topic consumption.
- Kafka Consumer is â€Šthe service that will be responsible for reading messages processing them according to the needs of your own business logic which in our case storing them in DB.
- We utilize Spring Data JPA, In memory H2DB to implement the data storage, which consume messages from the Kafka broker. Finally, the produced data of the IoT
  is stored in our DB for further processing.
- The user can query the readings of specific sensor groups
  
 
