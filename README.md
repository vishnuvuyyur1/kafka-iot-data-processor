# kafka-iot-data-processor
Kafka project <br>
![arc](https://user-images.githubusercontent.com/22782834/88284944-93ab9600-ccee-11ea-9790-5357636d209f.png)
- A pipeline architecture that consists of well-known open source tools to specifically integrate internet of things (IoT) data streams.
- The code demonstrate how to deal with IoT stream data that is generated by device equipped with sensing components(IOT devices) 
   by utilizing open source tools and frameworks to tackle data integration as well as scalable stream processing.  
- The architecture consists of several tools that are chained to build a pipeline. Apache Kafka a
  suitable intermediate tool for the data integration kicks in by triggering a schedule task which send out a value every second mimicing an IOT device as the entry point of published messages, 
- These messages are then forwarded to a Kafka broker running locally in order to fault-tolerant stream processing and parallel topic consumption.
- Kafka Consumer is â€Šthe service that will be responsible for reading messages processing them according to the needs of your own business logic which in our case storing them in DB.
- We utilize Spring Data JPA, In memory H2DB to implement the data storage, which consume messages from the Kafka broker. Finally, the produced data of the IoT
  is stored in our DB for further processing.
- The user can query the readings of specific sensor groups

## Tech stack
- Apache kafka 2+
- Java 11
- Spring Boot 2+
- Spring security
- JPA
- In Memory DB
  
 ## Running Instructions Locally
 Prerequisites:
 - Windows os
 - Download kafka from :https://kafka.apache.org/quickstart#quickstart_download
 - Unzip the folder using 7-zip or winrar
 - Rename the folder to kafka and place the folder in C: drive and the final path looks like C:\kafka
 
 Runnign the project
 - From command prompt Go to  C:\kafka
 - First statr the zookeeper cmd: .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
 - Next start kafka server cmd: .\bin\windows\kafka-server-start.bat .\config\server.properties
  - If you see error in Kafka server such then go to config/server.properties and add this listeners=PLAINTEXT://localhost:9092 is what the broker will use to create server sockets.
 - If you see error in Kafka server such as org.apache.kafka.clients.NetworkClient then go to config/server.properties and add this advertised.listeners=PLAINTEXT://localhost:9092 is what clients will use to connect to the brokers.
 - Next run the spring boot project from an IDE
 
 # API Documentation
  Base URL: http://localhost:8080/ <br>
  Operations:
  
  |No| Operation | Endpoint | Method
|----|---|---|---|
|1| start scheduling  |/start| POST |
|2| stop scheduling | /stop | POST |
|3| get query readings |/iotdata |GET | 

## 1. start scheduling
- URI: /start
- Method: POST
<br>
Request Body : None <br>
Request Body : Started Scheduling <br>

## 2. get query readings
- URI: /stop
- Method: POST
<br>
Request Body : None <br>
Request Body : Stopped Scheduling <br>

## 3. get query readings
- URI: /iotdata
- Method: GET
<br>
Request Body

  |Attributes|Type|Validation | Required |
|----|---|---|---|
|deviceType|ENUM | THERMOSTAT_METER/HEART_METER/CARFUEL_METER| yes|
|queryType|ENUM | AVERAGE/MAX/MIN | yes |

```
{
    "deviceType": "HEART_METER",
    "queryType": "MIN"
}
```
Response 
 |Attributes|Type|
|----|---|
|deviceType|ENUM | 
|queryType|ENUM | 
|queryValue|int | 

```
{
    "queryType": "MIN",
    "deviceType": "HEART_METER",
    "queryValue": "62"
}
```

